\documentclass[a4paper,man,natbib]{apa6}
%\usepackage[square]{natbib}
\usepackage{microtype}
\usepackage{mathtools} % needed
\usepackage{hyperref}
\usepackage{tabularx}
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}

\usepackage[normalem]{ulem}
\hypersetup{hidelinks=True}
\usepackage{lingex} % < MC's numbering

\usepackage{afterpage}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

\usepackage[modulo,displaymath,pagewise]{lineno}

\newcommand*{\smex}[1]{\textit{#1}} % 'small example'
\newcommand*{\spex}[1]{``{#1}''} % 'spoken example'
\newcommand*{\term}[1]{\emph{#1}} % introducing a new term
\newcommand*{\citegen}[1]{\citeauthor{#1}'s~(\citeyear{#1})}
\newcommand*{\SE}{\mathit{SE}} % fix funny "SE" spacing
\newcommand{\resultsLog}[3]{$\beta = #1$, $\textnormal{SE} = #2$, $p #3$}
\newcommand{\resultsLM}[3]{$\beta = #1$, $\textnormal{SE} = #2$, $t #3$}

\usepackage[obeyFinal,textsize=tiny,backgroundcolor=yellow!60,linecolor=black!60]{todonotes}
\setlength{\marginparwidth}{2cm}
\let\oldtodo\todo
\renewcommand*{\todo}[1]{\oldtodo[fancyline]{#1}}



\title{??}
\author{}
\affiliation{}
\ifapamodeman{\note{\begin{flushleft}%
\url{}
\end{flushleft}}}

\shorttitle{mtracker}

\abstract{}

\begin{document}
\maketitle
\linenumbers
\noindent


\section*{Intro}
Tracking how participants move a computer mouse is a comparatively recent method in behavioural psychology. 
By recording positions and trajectories of the cursor relative to specific responses on a screen, researchers study the influence of various experimental manipulations on the decisions which participants make during these experiments.
One area in which mouse-tracking has gained attention is in the context of language research - recording mouse movements alongside the presentation of speech allows researchers to track the time-course of lexical activations during real-time comprehension.
For example, \citet{Spivey?} tasked listeners with responding to spoken instructions such as \spex{Click the candle}, while viewing displays which depicted the target (candle) and a distractor. 
Listeners’ mouse trajectories showed a marked attraction towards distractors which shared the same phonological onset with the target word (e.g. candy) compared to distractors which did not (e.g. pickle)

%mouse vs eye
\citet{Allopenna1998} - eyes phonological competition. 
% problem 
takes fundamentally categorical measurements (fixations of one object or another over time) and produces 'continuous' functions. Thus, it can only approximate continuous central tendencies of group data.

This is because the pattern of fixations across all experimental trials
could simply reflect a cumulation of discrete interpretations on individual trials,
on which a listener either fixates the object
\citep{Farmer2005}

The output of this process is
a continuous stream of motor measures that reflect the evolving mental trajec-
tory, allowing the researcher to draw conclusions about the ongoing dynamics of
comprehension


We conducted a replication of the disfluency-deception bias \citep[see]{Loy2017} using mouse-tracking software developed %insert Graham, and Hannah's funding etc.
An open example of the experiment can be viewed at https://shire.ppls.ed.ac.uk/experiment/wKrEBWMCtF

Data was collected from both an online cohort and an in-lab cohort. 
This allows us to compare noisy web data with that collected in an controlled environment in which there is less (or no) variation in hardware, software, connection to the server, and practical considerations such as visual and audible distractions during the experiment.

%By combining this with the original data from \citep{Loy2017}
By combining data from the original experiment \cite{Loy2017}, and both sets of data in the current study, we present estimates with increased power... 

The study presented here is aimed at validating mouse-tracking software which runs on a server at the University of Edinburgh, allowing the collection of data via online services such as Amazon-Turk. An example of the experiment can be found at: 
https://shire.ppls.ed.ac.uk/experiment/wKrEBWMCtF


\section*{Methods}

\subsection*{materials}  

Visual stimuli consisted of the same 120 line drawings from Snodgrass and Vanderwart that were used in Loy et al.’s study, with the same subset of 20 used in critical trials. 
We used the same audio recordings from Loy et al. (Experiment 2) in which the speaker named an object as hiding the location of some treasure. As in Loy et al., the utterances were either fluent or contained a disfluency prior the critical noun:
“the treasure is behind the/thee - uh - <referent>”

\subsection*{procedure}

Experiment is presented on a 1024x700 display. If the resolution of the monitor is greater than this then the display is centered and the surrounding area is black. The experiment does not run on devices with a lower resolution (e.g. mobile devices). As in the original study, images are centred vertically and positioned such that the center of the images are 15% inwards from either edge of the display. 

Figure 1 shows the trial procedure.
A central click box is presented upon which the participants must click (in doing so centering the cursor).
After clicking on this box, the two objects (referent and distractor) appear.
After 1000ms, the playback of the utterance begins. 
The participant must then click on one of the objects on the screen, or else the trial will time out 5000ms after the recording ends. 
Upon clicking an object (or timeout), the central clickbox is presented, signifying the beginning of the next trial.
Prior to beginning the experiment, instructions (Figure 2) followed by a scoreboard (Figure 3) are presented on screen.


\subsection*{differences}

random allocation of trial order, pairings of referents/distractors, and left/right positioning of referent image, was not possible to encode on each run of the experiment. 
in loy - left/right was sampled on each trial, pairings of ref/dist and trial order were randomly allocated on each run of experiment.  

in the present study, relative on-screen positions (left/right) or referents/distractors were fully counterbalanced across items.
20 critical items were counterbalanced across four lists in which 5 fluent target left, 5 disfluent target right, 5 fluent target right, 5 disfluent left. 
these 4 lists were expanded to 44, each of which contained the 40 distractor referents, with randomly paired distractors, and randomly ordered. 

Mouse position is sampled only when the mouse is clicked or when the cursor is in motion (i.e. at an event). 
When the cursor is in motion, position is sampled at a rate of 62.5Hz, or every 16ms (Chrome on Linux with wired connection).

unlike Loy, there were no practice trials.  

In the original study, progression between trials required a central fixation point, and the cursor was hidden until utterance onset, at which point it was centered and made visible.
In the present study, the cursor is always visible, and participants center it themselves in progressing between trials. 

In the original paradigm, participants are shown a scoreboard at the onset of the experiment, and are told that they will collect points for correctly guessing the true location of the treasure. 25\% of filler trials presented participants with feedback stating that the trial was a “bonus round”, and they successfully located the treasure (regardless of which object they clicked).

Using our software, it is not possible to give feedback on trials. 

attention check trials  
Instead, we include four “bonus rounds” interspersed randomly throughout the experiment, which serve as attention check trials, to ensure that participants are attending to the experiment and to the audio, and not simply clicking through whilst doing something else.  
These bonus rounds are procedurally the same as experimental trials in that they are presented as two objects and along with a spoken utterance. 
Each bonus round shows two further images from Snodgrass and Vanderwart (1980), one of which is an animal, and one of which is not. Participants hear an utterance (from a different speaker) saying “This is a bonus round! Simply click on the animal to score extra points!”. 
Participants are informed in the instructions that bonus rounds are not lies. 


\subsection*{Participants}

Mturk data collection was more difficult (see figure X).%jk insert flowchart
this was the first use of mtracking software "in the wild" and there were some initial teething problems, such as certain combinations of browsers and operating systems not collecting any data, or not providing accurate timestamps. 
Fifty-three mturk IDs located in the UK submitted HITs for this initial phase, with 7 taking part multiple times and submitting multiple HITs (despite instruction not to do so).
%this is from mturk info. batches <8 ("SALINGER") were before mturk id collection in mtrack software
Once technical problems such as these were fixed the experiment was re-opened, with participation conditional upon a HIT approval rating of at least 1000, and payment conditional upon a) one HIT per mturk ID, and b) valid completion of the game. 
This latter condition was implemented because in the initial phase it transpired that many participants were not completing the experiment correctly (i.e., were clicking an image before hearing the audio and quickly progressing through the trials). 

160 further instances (after the initial testing phase) of the experiment were opened to mturkers in the UK. 
Forty-eight instances belonged to mturk IDs who had taken part on a previous occasion (either in this set or during the initial testing phase set).
These subsequent instances (48) were excluded.

The remaining 112 instances belonged to 112 distinct mturk IDs, with each instance being the first time that mturk ID had opened the experiment. 
Of these 112 mturk IDs, 82 were self-reported monolingual speakers of English, 67 of which met all of the following criteria for valid completion of the game:  
\begin{itemize}
\item completed upwards of 55 out of the 64 trials (60 plus 4 attention check trials)
\item moved the mouse in at least 10 out of 20 critical trials
\item gave a correct response to 2 out of the 4 attention check questions (see below)
\item clicked the mouse after the onset of the referent-noun in at least 90\% of the trials they completed
\item clicked the mouse on average at least 200~ms after the onset of the referent noun
\item did not make 90\% or more of their mouse clicks on the same side of the screen
\end{itemize}

Lab data
28 participants
22 monolingual

\section*{Analysis}

\section*{Results}

\end{document}
